<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
	<title>Raghu Meka</title>
	<link rel="stylesheet" type="text/css" href="main.css" />
<script type="text/javascript">

        <!--
              function toggle(id)
              {
                  div_el = document.getElementById(id);
                  if (div_el.style.display != 'none')
                  {
                     div_el.style.display='none';
                  }
                  else
                  {
                     div_el.style.display='block';
                  };
              };
          -->
</script>

</head>
<body>
<div class="container">
<div class="container">
<div class="navbar">
<ul id="navbar">
<li><a class="nav" href="index.html">Raghu Meka</a></li>
<div style="float:right"><li><a class="nav" href="research.html">Research</a><li>&emsp;&emsp;
<li><a class="nav" href="talks.html">Talks</a><li></div>
</ul>
</div>
<br>
<div style="float:left; width:800px; margin-left:0em">
<font size="5">
My main interests are in complexity theory, learning theory, algorithm design.
More generally, I like probability and combinatorics related things.  </font>
<br><br>
<div class="banner">Theory Stuff</div>

<div class="paper">
<div class="ptitle">
	Leakage-Resilient Secret Sharing</div>
	<div class="pwho">Ashutosh Kumar, Raghu Meka, Amit Sahai</div>
	<div class="pwho"> <a class=plink href="https://eprint.iacr.org/2018/1138">ePrint</a></div>
	</div>
	
<div class="paper">
<div class="ptitle">
	On the Discrepancy of Random Low-Degree Set Systems</div>
	<div class="pwho"><strong>SODA 2019.</strong>Nikhil Bansal, Raghu Meka</div>
	<div class="pwho"> <a class=plink href="https://arxiv.org/abs/1810.03374">arXiv</a></div>
	</div>

<div class="paper">
<div class="ptitle">
Pseudorandom Generators for Width-3 Branching Programs</div>
	<div class="pwho"><strong>STOC 2019.</strong>Raghu Meka, Omer Reingold, Avishay Tal</div>
<div class="pwho"> <a class=plink href="https://arxiv.org/abs/1806.04256">arXiv</a></div>
</div>

<div class="paper">
<div class="ptitle">
	Efficient Algorithms for Outlier-Robust Regression
</div>
<div class="pwho"><strong>COLT 2018.</strong> Adam Klivans, Pravesh Kothari, Raghu Meka</div>
<div class="pwho"> <a class=plink href="https://arxiv.org/abs/1803.03241">arXiv</a></div>
</div>

<div class="paper">
<div class="ptitle">
	Learning One Convolutional Layer with Overlapping Patches
</div>
<div class="pwho"><strong>ICML 2018.</strong> Surbhi Goel, Adam Klivans, Raghu Meka</div>
<div class="pwho"> <a class=plink href="https://arxiv.org/abs/1802.02547">arXiv</a></div>
</div>

<div class="paper">
<div class="ptitle">
Learning Graphical Models using Multiplicative Weights</div>
<div class="pwho"><strong>FOCS 2017.</strong> Adam Klivans, Raghu Meka</div>
<a class=abstractl onclick="toggle(&quot;&quot;)">ABSTRACT</a> <a class=plink href="https://arxiv.org/abs/1706.06274">arXiv</a>
<div class="abstract" style="display:none;">
</div>
</div>


<div class="paper">
<div class="ptitle">
Approximating Rectangles by Juntas and Weakly-Exponential Lower Bounds for LP Relaxations of CSPs</div>
<div class="pwho"><strong>STOC 2017.</strong> Pravesh Kothari, Prasad
  Raghavendra, Raghu Meka</div>
  <div class="pwho">Invited to SICOMP <b>Special Issue</b> on STOC 2017</div>
<a class=abstractl onclick="toggle(&quot;&quot;)">ABSTRACT</a> <a class=plink href="https://arxiv.org/abs/1610.02704">arXiv</a>
<div class="abstract" style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Explicit resilient functions matching Ajtai-Linial</div>
<div class="pwho"><strong>SODA 2017.</strong> Raghu Meka</div>
<a class=abstractl onclick="toggle(&quot;&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/1509.00092">arXiv</a>
<div class="abstract" style="display:none;">
</div>
</div>


<div class="paper">
<div class="ptitle">
Anti-concentration for polynomials of independent random variables</div>
<div class="pwho"><strong>Theory of Computing, Volume 12.</strong> Raghu Meka, Oanh
  Nguyen, Van Vu.</div>
<a class=abstractl onclick="toggle(&quot;&quot;)">ABSTRACT</a> <a
  class=plink
  href="http://theoryofcomputing.org/articles/v012a011/">TOC</a>
<div class="abstract" style="display:none;">
</div>
</div>


<div class="paper">
<div class="ptitle">
Pseudorandomness via the discrete Fourier transform</div>
<div class="pwho"><strong>FOCS 2015</strong>. Parikshit Gopalan,
  Daniel Kane, Raghu Meka.</div>
<div class="pwho">Invited to SICOMP <b>Special Issue</b> on FOCS 2015</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/1506.04350">arXiv</a>
<div class="abstract" style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Sum-of-squares lower bounds for planted clique</div>
<div class="pwho"><strong>STOC 2015</strong>. Raghu Meka, Aaron
  Potechin, Avi Wigderson.</div>
<div class="pwho">Invited to SICOMP <b>Special Issue</b> on STOC 2015</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/1503.06447">arXiv</a>
<div class="abstract" style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Almost Optimal Pseudorandom Generators for Spherical Caps</div>
<div class="pwho"><strong>STOC 2015</strong>. Pravesh Kothari, Raghu Meka.</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/1411.6299">arXiv</a>
<div class="abstract" style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Rectangles are Nonnegative Juntas</div>
<div class="pwho"><strong>STOC 2015</strong>. Mika G&ouml&oumls, Shachar Lovett, Raghu Meka, Thomas Watson, David Zuckerman.</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="http://eccc.hpi-web.de/report/2014/147/">ECCC</a>
<div class="abstract" style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Communication with Imperfectly Shared Randomness</div>
<div class="pwho"><strong>ITCS 2015</strong>. Clement Canonne, Venkatesan Guruswami, Raghu Meka, Madhu Sudan.</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a>
<a class=plink href="http://arxiv.org/abs/1411.3603">arXiv</a>  <a class=plink href="http://newsoffice.mit.edu/2014/more-reliable-communication-protocols-1212">MIT-NEWS</a>
<div class="abstract" style="display:none;">
</div>
</div>


<div class="paper">
<div class="ptitle">
Fast Pseudorandomness for Independence and Load Balancing</div>
<div class="pwho"><strong>ICALP 2014</strong>. Raghu Meka, Omer Reingold, Guy Rothblum, Ron Rothblum.</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="pubs/eps_bias.pdf">PDF</a>
<div class="abstract" style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Volumetric Spanners an Exploration Basis for Learning</div>
<div class="pwho"><strong>COLT 2014</strong>. Elad Hazan, Zohar Karnin, Raghu Meka.</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="http://jmlr.org/proceedings/papers/v35/hazan14b.html">JMLR</a>
<div class="abstract" style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Computational Limits for Matrix Completion</div>
<div class="pwho"><strong>COLT 2014</strong>. Moritz Hardt, Raghu Meka, Prasad Raghavendra, Benjamin Weitz.</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="http://jmlr.org/proceedings/papers/v35/hardt14b.html">JMLR</a>
<div class="abstract" style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Deterministic Coupon Collection and Better Strong Dispersers</div>
<div class="pwho"><strong>RANDOM 2014</strong>. Raghu Meka, Omer Reingold, Yuan Zhou.</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="pubs/dispersers.pdf">PDF</a>
<div class="abstract"  style="display:none;">
</div>
</div>

<div class="paper">
<div class="ptitle">
Learning Halfspaces under Log-Concave Distributions</div>
<div class="pwho"><strong>COLT 2013</strong>. Daniel Kane, Adam Klivans and Raghu Meka.</div>
<a class=abstractl onclick="toggle(&quot;mompoly&quot;)">ABSTRACT</a> <a class=plink href="http://jmlr.org/proceedings/papers/v30/Kane13.html">JMLR</a>
<div class="abstract" id="mompoly" style="display:none;">
We give the first polynomial-time algorithm for agnostically learning any function of a constant number of halfspaces with respect to any log-concave distribution (for any constant accuracy parameter). This result was not known even for the case of PAC learning the intersection of two halfspaces. We give two very different proofs of this result. The first develops a theory of polynomial approximation for log-concave measures and constructs a low-degree L1 polynomial approximator for sufficiently smooth functions. The second uses techniques related to the classical moment problem to obtain sandwiching polynomials. Both approaches deviate significantly from known Fourier-based methods, where essentially all previous work required the underlying distribution to have some product structure. Additionally, we show that in the smoothed-analysis setting, the above results hold with respect to distributions that have sub-exponential tails, a property satisfied by many natural and well-studied distributions in machine learning.
</div>
</div>


<div class="paper">
<div class="ptitle">
A PRG for Lipschitz Functions of Polynomials with Applications to Sparsest Cut</div>
<div class="pwho"><strong>STOC 2013</strong>. Daniel Kane and Raghu Meka.</div>
<a class=abstractl onclick="toggle(&quot;sparsestcut&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/1211.1109">arXiv</a>
<div class="abstract" id="sparsestcut" style="display:none;">
We give improved pseudorandom generators (PRGs) for Lipschitz functions of low-degree polynomials over the hypercube. These are functions of the form psi(P(x)), where P is a low-degree polynomial and psi is a function with small Lipschitz constant. PRGs for smooth functions of low-degree polynomials have received a lot of attention recently and play an important role in constructing PRGs for the natural class of polynomial threshold functions. In spite of the recent progress, no nontrivial PRGs were known for fooling Lipschitz functions of degree O(log n) polynomials even for constant error rate. In this work, we give the first such generator obtaining a seed-length of (log n)\tilde{O}(d^2/eps^2) for fooling degree d polynomials with error eps. Previous generators had an exponential dependence on the degree.<br>
We use our PRG to get better integrality gap instances for sparsest cut, a fundamental problem in graph theory with many applications in graph optimization. We give an instance of uniform sparsest cut for which a powerful semi-definite relaxation (SDP) first introduced by Goemans and Linial and studied in the seminal work of Arora, Rao and Vazirani has an integrality gap of exp(\Omega((log log n)^{1/2})). Understanding the performance of the Goemans-Linial SDP for uniform sparsest cut is an important open problem in approximation algorithms and metric embeddings and our work gives a near-exponential improvement over previous lower bounds which achieved a gap of \Omega(log log n).
</div>
</div>

<div class="paper">
<div class="ptitle">
Better Pseudorandom Generators from Milder Pseudorandom Restrictions</div>
<div class="pwho"><strong>FOCS 2012</strong>. Parikshit Gopalan, Raghu Meka, Omer Reingold, Luca Trevisan, Salil Vadhan.</div>
<a class=abstractl onclick="toggle(&quot;bettermilder&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/1210.0049">arXiv</a>
<div class="abstract" id="bettermilder" style="display:none;">
We present an iterative approach to constructing pseudorandom generators, based on the repeated application of mild pseudorandom restrictions. We use this template to construct pseudorandom generators for combinatorial rectangles and read-once CNFs and a hitting set generator for width-3 branching programs, all of which achieve near-optimal seed-length even in the low-error regime: We get seed-length O(log (n/epsilon)) for error epsilon. Previously, only constructions with seed-length O(\log^{3/2} n) or O(\log^2 n) were known for these classes with polynomially small error.<br>
The (pseudo)random restrictions we use are milder than those typically used for proving circuit lower bounds in that we only set a constant fraction of the bits at a time. While such restrictions do not simplify the functions drastically, we show that they can be derandomized using small-bias spaces.</div></div>

<div class="paper">
<div class="ptitle">
Pseudorandomness from Shrinkage</div>
<div class="pwho"><b>FOCS 2012</b>. Russell Impagliazzo, Raghu Meka, David Zuckerman</div>
<a class=abstractl onclick="toggle(&quot;shrinkage&quot;)">ABSTRACT</a> <a class=plink href="http://eccc.hpi-web.de/report/2012/057/">ECCC</a>
<div class="abstract" id="shrinkage" style="display:none;">
One powerful theme in complexity theory and pseudorandomness in the past few decades has been the use of lower bounds to give pseudorandom generators (PRGs). However, the general results using this hardness vs. randomness paradigm suffer a quantitative loss in parameters, and hence do not give nontrivial implications for models where we only know lower bounds of a fixed polynomial. We show that when such lower bounds are proved using random restrictions, we can indeed construct PRGs which are essentially best possible without in turn improving the lower bounds.<br>

More specifically, say that a circuit family has shrinkage exponent Gamma if a random restriction leaving a p fraction of variables unset shrinks the size of any circuit in the family by a factor of p^Gamma. Our PRG uses a seed of length roughly s^{1/(Gamma+1)} to fool circuits in the family of size s. By instantiating this generic construction, we get PRGs for the following classes:<br>
1) de Morgan formulas of size s, seed length s^{1/3+o(1)}.<br>
2) Formulas over an arbitrary basis of size s, seed length s^{1/2+o(1)}.<br>
3) Read-once formulas, seed length s^{.234...}.<br>
4) Branching programs of size s, seed length s^{1/2+o(1)}.<br>

The previous best PRGs known for these classes used seeds of length bigger than n/2  to output n bits, and worked only when the size s=O(n).
</div>
</div>

<div class="paper">
<div class="ptitle">
Constructive Discrepancy Minimization by Walking on The Edges</div>
<div class="pwho"><b>FOCS 2012</b>. Shachar Lovett, Raghu Meka</div>
<div class="pwho">Invited to SICOMP <b>Special Issue</b> on FOCS 2012</div>
<a class=abstractl onclick="toggle(&quot;edgewalk&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/1203.5747">arXiv</a>
<div class="abstract" id="edgewalk" style="display:none;">
Minimizing the discrepancy of a set system is a fundamental problem in combinatorics. One of the cornerstones in this area is the celebrated six standard deviations result of Spencer (AMS 1985): In any system of n sets in a universe of size n, there always exists a coloring which achieves discrepancy 6\sqrt{n}. The original proof of Spencer was existential in nature, and did not give an efficient algorithm to find such a coloring. Recently, a breakthrough work of Bansal (FOCS 2010) gave an efficient algorithm which finds such a coloring. His algorithm was based on an SDP relaxation of the discrepancy problem and a clever rounding procedure. In this work we give a new randomized algorithm to find a coloring as in Spencer's result based on a restricted random walk we call "Edge-Walk". Our algorithm and its analysis use only basic linear algebra and is "truly" constructive in that it does not appeal to the existential arguments, giving a new proof of Spencer's theorem and the partial coloring lemma.
</div>
</div>


<div class="paper">
<div class="ptitle">
A PTAS for Computing the Supremum of Gaussian Processes</div>
<div class="pwho"><b>FOCS 2012</b>. Raghu Meka</div>
<div class="pwho">Annals of Applied Probability, Volume 25, Issue 2</div>
<a class=abstractl onclick="toggle(&quot;supg&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/1202.4970">arXiv</a>
<div class="abstract" id="supg" style="display:none;">
We give a polynomial time approximation scheme (PTAS) for computing the supremum of a Gaussian process. That is, given a finite set of d-dimensional vectors V, we compute a (1+epsilon)-factor approximation to Ex_{X standard Gaussian}[sup_{v in V}|<v,X>|] deterministically in time poly(d) |V|^{O_epsilon(1)}. Previously, only a constant factor deterministic polynomial time approximation algorithm was known due to the work of Ding, Lee and Peres. This answers an open question of Lee and Ding.<br><br>
The study of supremum of Gaussian processes is of considerable importance in probability with applications in functional analysis, convex geometry, and in light of the recent work of Ding, Lee and Peres, to random walks on finite graphs. As such our result could be of use elsewhere. In particular, combining with the recent work of Ding, our result yields a PTAS for computing the cover time of bounded degree graphs. Previously, such algorithms were known only for trees.<br><br>
Along the way, we also give an explicit oblivious linear estimator for semi-norms in Gaussian space with optimal query complexity.
</div>
</div>


<div class="paper">
<div class="ptitle">
Making the long code shorter, with applications to the Unique Games Conjecture</div>
<div class="pwho"><b>FOCS 2012</b>. Boaz Barak, Parikshit Gopalan, Johan Hastad, Raghu Meka, Prasad Raghavendra, David Steurer</div>
<div class="pwho">Invited to SICOMP <b>Special Issue</b> on FOCS 2012</div>
<a class=abstractl onclick="toggle(&quot;sse&quot;)">ABSTRACT</a> <a class=plink href="http://eccc.uni-trier.de/report/2011/142">ECCC</a>
<div class="abstract" id="sse" style="display:none;">
The long code is a central tool in hardness of approximation, especially in
questions related to the unique games conjecture. We construct a new code that
is exponentially more ecient, but can still be used in many of these applications.
Using the new code we obtain exponential improvements over several known results,
including the following:<br>

(1) We construct a small set expander graph with $exp(log^{Omega(1)} n)$ large eigenvalues. This answers an open question of Arora, Barak and Steurer (FOCS 2010) who asked whether one can improve over the noise graph on the Boolean hypercube that has poly(log n) such eigenvalues.<br>

(2) A gadget that reduces unique games instances with linear constraints modulo K into instances with constant size alphabet space with a quasipolynomial (in K) blowup, improving over the previously known gadget with blowup of exp(K).<br>

(3) An n variable integrality gap for Unique Games that that survives exp(poly(loglogn)) rounds of the SDP + Sherali Adams hierarchy, improving on the previously known bound of poly(loglogn).<br>

We show a connection between the local testability of linear codes and small set
expansion in certain related Cayley graphs, and use this connection to derandomize
the noise graph on the Boolean hypercube.
</div>
</div>

<div class="paper">
<div class="ptitle">
Learning Functions of Halfspaces using Prefix Covers</div>
<div class="pwho"><b>COLT 2012</b>. Parikshit Gopalan, Adam Klivans, Raghu Meka</div>
</div>

<div class="paper">
<div class="ptitle">
DNF Sparsification and Faster Deterministic Counting</div>
<div class="pwho"><b>CCC 2012</b>. Parikshit Gopalan, Raghu Meka, Omer Reingold</div>
<div class="pwho">Invited to Computational Complexity <b>Special Issue</b> on CCC 2012</div>
<a class=abstractl onclick="toggle(&quot;dnfcount&quot;)">ABSTRACT</a> <a class=plink href="http://eccc.hpi-web.de/report/2012/060">ECCC</a>
<div class="abstract" id="dnfcount" style="display:none;">
We give a faster deterministic algorithm for approximately counting the number of satisfying solutions to a DNF or CNF. Given a DNF (or CNF) f on n variables we give a deterministic n^{\tilde{O}((log log n)^2)} time algorithm that computes an (additive) epsilon approximation to the fraction of satisfying assignments of f for epsilon = 1/poly(log n). The previous best algorithm due to Luby and Velickovic from nearly two decades ago had a run-time of n^{exp(O(sqrt{log log n}))}.<br><br>

A crucial ingredient in our algorithm is a structural result which allows us to sparsify any small-width DNF formula. It says that any width w DNF (irrespective of the number of terms) can be epsilon-approximated by a width w DNF with at most (w log(1/epsilon))^{O(w)} terms. Further, our approximating DNFs have an additional ``sandwiching'' property which is crucial for applications to derandomization.
</div>
</div>

<div class="paper">
<div class="ptitle">
Computational Applications of Invariance Principles</div>
<div class="pwho">Dissertation.
 <a class=plink href="pubs/thesisf.pdf">PDF</a></div>
<div class="pwho">Bert Kay <b>Best Dissertation Award</b> in Computer Science</div>
</div>


<div class="paper">
<div class="ptitle">
PTAS for Knapsack and Related Problems using Branching Programs</div>
<div class="pwho"><b>FOCS 2011</b>. Parikshit Gopalan, Adam Klivans and Raghu Meka<br>
Conference version to be merged with <a href="http://arxiv.org/abs/1008.1687">this</a> paper by Daniel Stefankovich, Santhosh Vempala and Eric Vigoda.</div>
<a class=abstractl onclick="toggle(&quot;knapsk&quot;)">ABSTRACT</a> <a class=plink href="http://eccc.uni-trier.de/report/2010/133">ECCC</a>
<div class="abstract" id="knapsk" style="display:none;">
We give a deterministic, polynomial-time algorithm for approximately counting the number of {0,1}-solutions to any instance of the knapsack problem. On an instance of length n with total weight W and accuracy parameter eps, our algorithm produces a (1 + eps)-multiplicative approximation in time poly(n,log W,1/eps). We also give algorithms with identical guarantees for general integer knapsack, the multidimensional knapsack problem (with a constant number of constraints) and for contingency tables (with a constant number of rows). Previously, only randomized approximation schemes were known for these problems due to work by Morris and Sinclair and work by Dyer.<br><br>

Our algorithms work by constructing small-width, read-once branching programs for approximating the underlying solution space under a carefully chosen distribution. As a byproduct of this approach, we obtain new query algorithms for learning functions of k halfspaces with respect to the uniform distribution on {0,1}^n. The running time of our algorithm is polynomial in the accuracy parameter eps. Previously even for the case of k=2, only algorithms with an exponential dependence on eps were known.
</div>
</div>


<div class="paper">
<div class="ptitle">
Almost Optimal Explicit Johnson-Lindenstrauss Transformations</div>
<div class="pwho"><b>Random 2011</b>. Daniel Kane, Raghu Meka and Jelani Nelson</div>
</div>

<div class="paper">
<div class="ptitle">
Pseudorandom Generators for Combinatorial Shapes</div>
<div class="pwho"><b>STOC 2011</b>. Parikshit Gopalan, Raghu Meka, Omer Reingold and David Zuckerman</div>
<div class="pwho">To appear in <b>SICOMP</b></div>
<a class=abstractl onclick="toggle(&quot;prgcs&quot;)">ABSTRACT</a> <a class=plink href="http://eccc.uni-trier.de/report/2010/176">ECCC</a>
<div class="abstract" id="prgcs" style="display:none;">
We construct pseudorandom generators for {combinatorial shapes}, which substantially generalize combinatorial rectangles, small-bias spaces, 0/1 halfspaces, and 0/1 modular sums. A Boolean function f with domain [m]^n is an (m,n)-combinatorial shape if there exist sets A_1,\ldots,A_n \subseteq [m] such that f is given by a symmetric Boolean function h applied to the  arguments 1(x_1 in A_1), 1(x_2 in A_2),..., 1(x_n in A_n). Our generator uses seed length O(log m + log n + log^2(1/eps)) to get error eps. When m =2, this gives the first generator of seed length O(log n) which fools all weight-based tests, meaning that the distribution of the weight of any subset is eps-close to the appropriate binomial distribution in statistical distance.<br><br>

For our proof we give a simple lemma which allows us to convert closeness in Kolmogorov (cdf) distance to closeness in statistical distance. As a corollary of our technique, we give an alternative proof of a powerful variant of the classical central limit theorem showing convergence in statistical distance, instead of the usual Kolmogorov distance.
</div>
</div>


<div class="paper">
<div class="ptitle">
An Invariance Principle for Polytopes</div>
<div class="pwho"><b>STOC 2010</b>. Prahladh Harsha, Adam Klivans and Raghu Meka</div>
<div class="pwho">Journal of the ACM <b>(JACM)</b>, Volume 59, Issue 6</div>
<a class=abstractl onclick="toggle(&quot;ippoly&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/0912.4884">arXiv</a> <a class=plink href="http://eccc.uni-trier.de/report/2009/144">ECCC</a>
<div class="abstract" id="ippoly" style="display:none;">
Let X be randomly chosen from {-1,1}^n, and let Y be randomly chosen from the standard spherical Gaussian on R^n. For any (possibly unbounded) polytope P formed by the intersection of k halfspaces, we prove that <br>
&nbsp&nbsp&nbsp&nbsp&nbsp   |Pr [X belongs to P] - Pr [Y belongs to P]| < log^{8/5}k * Delta, <br>
where Delta is a parameter that is small for polytopes formed by the intersection of "regular" halfspaces (i.e., halfspaces with low influence). <br><br>

The novelty of our invariance principle is the polylogarithmic dependence on k. Previously, only bounds that were at least linear in k were known. We give two important applications of our main result:<br><br>

(1) A polylogarithmic in k bound on the Boolean noise sensitivity of intersections of k "regular" halfspaces (previous work gave bounds linear in k). <br>

(2) A pseudorandom generator (PRG) with seed length O((log n)*poly(log k,1/delta)) that delta-fools all polytopes with k faces with respect to the Gaussian distribution. <br><br>

We also obtain PRGs with similar parameters that fool polytopes formed by intersection of regular halfspaces over the hypercube. Using our PRG constructions, we obtain the first deterministic quasi-polynomial time algorithms for approximately counting the number of solutions to a broad class of integer programs, including dense covering problems and contingency tables.
</div>
</div>


<div class="paper">
<div class="ptitle">
Pseudorandom Generators for Polynomial Threshold Functions</div>
<div class="pwho"><b>STOC 2010</b>. Raghu Meka and David Zuckerman</div>
<div class="pwho">Invited to SICOMP <b>Special Issue</b> on STOC 2010</div>
<a class=abstractl onclick="toggle(&quot;prgptf&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/0910.4122">arXiv</a>
<div class="abstract" id="prgptf" style="display:none;">
We study the natural question of constructing pseudorandom generators (PRGs) for low-degree polynomial threshold functions (PTFs). We give a PRG with seed-length log n/eps^{O(d)} fooling degree d PTFs with error at most eps. Previously, no nontrivial constructions were known even for quadratic threshold functions and constant error eps. For the class of degree 1 threshold functions or halfspaces, we construct PRGs with much better dependence on the error parameter eps and obtain the following results.<br><br>
1) A PRG with seed length O(log n log(1/eps)) for eps > 1/poly(n).<br>
2) A PRG with seed length O(log n) for eps > 1/poly(log n).<br><br>

Previously, only PRGs with seed length O(log n log^2(1/eps)/eps^2) were known for halfspaces. We also obtain PRGs with similar seed lengths for fooling halfspaces over the n-dimensional unit sphere.<br><br>

The main theme of our constructions and analysis is the use of invariance principles to construct pseudorandom generators. We also introduce the notion of monotone read-once branching programs, which is key to improving the dependence on the error rate eps for halfspaces. These techniques may be of independent interest.
</div>
</div>

<div class="paper">
<div class="ptitle">
Bounding the Sensitivity of Polynomial Threshold Functions</div>
<div class="pwho"><b>STOC 2010</b>. Prahladh Harsha, Adam Klivans and Raghu Meka.Conference version to be merged with <a href="http://arxiv.org/abs/0909.5011">this</a> paper by Ilias Diakonikolas, Prasad Raghavendra, Rocco A. Servedio, Li-Yang Tan.
</div>
<div class="pwho">Invited to a <b>Special Issue</b> of Theory of Computing.</div>
<a class=abstractl onclick="toggle(&quot;ptf09&quot;)">ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/0909.5175">arXiv</a>
<div class="abstract" id="ptf09" style="display:none;">
We give the first non-trivial upper bounds on the average sensitivity and noise sensitivity of polynomial threshold functions. More specifically, for a Boolean function f on n variables equal to the sign of a real, multivariate polynomial of total degree d we prove<br>
1) The average sensitivity of f is at most O(n^{1-1/(4d+3)}) (we also give a simple combinatorial proof of the bound O(n^{1-1/2^d}).<br>
2) The noise sensitivity of f with noise rate \delta is at most O(\delta^{1/(4d+6)}).<br>
Previously, only bounds for the linear case were known. Along the way we show new structural theorems about random restrictions of polynomial threshold functions obtained via hypercontractivity. These structural results may be of independent interest as they provide a generic template for transforming problems related to polynomial threshold functions defined on the Boolean hypercube to polynomial threshold functions defined in Gaussian space.
</div>
</div>

<div class="paper">
<div class="ptitle">
Small-Bias Spaces for Group Products</div>
<div class="pwho"><b>Random 2009</b>. Raghu Meka and David Zuckerman</div>
<a class=abstractl onclick="toggle(&quot;rand09&quot;)">
      ABSTRACT</a> <a class=plink href="pubs/genepsilon.pdf">PDF</a>
<div class="abstract" id="rand09" style="display:none;">
	Small-bias, or $\epsilon$-biased, spaces have found many applications in complexity theory, coding theory, and derandomization. We generalize the notion of small-bias spaces to the setting of group products. Besides being natural, our extension captures some of the difficulties in constructing pseudorandom generators for constant-width branching programs - a longstanding open problem. We provide an efficient deterministic construction of small-bias spaces for solvable groups. Our construction exploits the fact that solvable groups have nontrivial normal subgroups that are abelian and builds on the construction of Azar et al.~\cite{azarmotwani} for abelian groups. For arbitrary finite groups, we give an efficient deterministic construction achieving constant bias. We also construct pseudorandom generators fooling linear functions mod $p$ for primes $p$.
</div>
</div>
<br>
<div class="banner">Datamining Stuff</div>
<div class="paper">
<div class="ptitle">Guaranteed Rank Minimization via Singular Value Projection</div>
<div class="pwho"><b>NIPS 2010</b>. Prateek Jain, Raghu Meka and Inderjit Dhillon.</div>
<a class=abstractl onclick="toggle(&quot;svp&quot;)">
      ABSTRACT</a> <a class=plink href="http://arxiv.org/abs/0909.5457">arXiv</a> <a class=plink href="http://www.cs.utexas.edu/~pjain/svp">Code</a>
<div class="abstract" id="svp" style="display:none;">
Minimizing the rank of a matrix subject to affine constraints is a fundamental problem with many important applications in machine learning and statistics. In this paper we propose a simple and fast algorithm SVP (Singular Value Projection) for rank minimization with affine constraints (ARMP) and show that SVP recovers the minimum rank solution for affine constraints that satisfy the "restricted isometry property" and show robustness of our method to noise. Our results improve upon a recent breakthrough by Recht, Fazel and Parillo (RFP07) and Lee and Bresler (LB09) in
 three significant ways:<br><br>
1) our method (SVP) is significantly simpler to analyze and easier to implement,<br>
2) we give recovery guarantees under strictly weaker isometry assumptions<br>
3) we give geometric convergence guarantees for SVP even in presense of noise and, as demonstrated empirically, SVP is significantly faster on real-world and
synthetic problems.<br><br>
In addition, we address the practically important problem of low-rank matrix completion (MCP), which can be seen as a special case of ARMP. We empirically demonstrate that our algorithm recovers low-rank incoherent matrices from an almost optimal number of uniformly sampled entries. We make partial progress towards proving exact recovery and provide some intuition for the strong performance of SVP applied to matrix completion by showing a more restricted isometry property. Our algorithm outperforms existing methods, such as those of \cite{RFP07,CR08,CT09,CCS08,KOM09,LB09}, for ARMP and the matrix-completion problem by an order of magnitude and is also significantly more robust to noise.
</div>
</div>


<div class="paper">
<div class="ptitle">Matrix Completion from Power-Law Distributed Samples</div>
<div class="pwho"><b>NIPS 2009</b>. Raghu Meka, Prateek Jain and Inderjit Dhillon.</div>
<a class=abstractl onclick="toggle(&quot;nips09&quot;)">
      ABSTRACT</a> <a class=plink href="pubs/powerlawmc.pdf">PDF</a>
<div class="abstract" id="nips09" style="display:none;">
The low-rank matrix completion problem is a fundamental problem with many important applications. Recently, \cite{candesrecht},\cite{montanari} and \cite{candestao} obtained the first non-trivial theoretical results for the problem assuming that the observed entries are sampled uniformly at random. Unfortunately, most real-world datasets do not satisfy this assumption, but instead exhibit power-law distributed samples. In this paper, we propose a graph theoretic approach to matrix completion that solves the problem for more realistic sampling models. Our method is easier to analyze than previous methods with the analysis reducing to computing the threshold for {\sl complete cascades} in random graphs, a problem of independent interest. By analyzing the graph theoretic problem, we show that our method achieves exact recovery when the observed entries are sampled from the Chung-Lu-Vu model, which can generate power-law distributed graphs. We also hypothesize that our algorithm solves the matrix completion problem from an optimal number of entries for the popular preferential attachment model and provide strong empirical evidence for the claim. Furthermore, our method is easier to implement and is substantially faster than existing methods. We demonstrate the effectiveness of our method on examples when the low-rank matrix is sampled according to the prevalent random graph models for complex networks and also on the Netflix challenge dataset.
</div>
</div>


<div class="paper">
<div class="ptitle">
Rank Minimization via Online Learning</div>
<div class="pwho"><b>ICML 2008</b>. Raghu Meka, Prateek Jain, Constantine Caramanis and Inderjit Dhillon</div>
<a class=abstractl onclick="toggle(&quot;icml08&quot;)">
      ABSTRACT</a> <a class=plink href="http://dblp.uni-trier.de/rec/bibtex/conf/icml/MekaJCD08">BibTex</a> <a class=plink href="pubs/icml08.pdf">PDF</a>
<div class="abstract" id="icml08" style="display:none;">
Minimum rank problems arise frequently in machine learning applications and are notoriously difficult to solve due to the non-convex nature of the rank objective. In this paper, we present the first online learning approach for the problem of rank minimization of matrices over polyhedral sets. In particular, we present two online learning algorithms for rank minimization - our first algorithm is a multiplicative update method based on a generalized experts framework, while our second algorithm is a novel application of the online convex programming framework \cite{zinkevich}. In the latter, we flip the role of the decision maker by making the decision maker search over the constraint space instead of feasible points, as is usually the case in online convex programming. A salient feature of our online learning approach is that it allows us to give provable approximation guarantees for the rank minimization problem over polyhedral sets. We demonstrate the effectiveness of our methods on synthetic examples, and on the real-life application of low-rank kernel learning. </div>
</div>
<div class="paper">
<div class="ptitle">
Simultaneous Unsupervised Learning of Disparate Clusterings</div>
<div class="pwho"><b>SDM 2008</b>. Prateek Jain, Raghu Meka and Inderjit Dhillon.<br>Journal Version: Statistical Analysis and Data Mining, Volume 1, Issue 3.</div>
<a class=abstractl onclick="toggle(&quot;sdm08&quot;)">
      ABSTRACT</a> <a class=plink href="http://dblp.uni-trier.de/rec/bibtex/journals/sadm/JainMD08">BibTex</a> <a class=plink href="pubs/sdm08.pdf">PDF</a> <a class=sbox>Best Paper Runner-up</a>
<div class="abstract" id="sdm08" style="display:none;">
Most clustering algorithms produce a single clustering for a given data set even when the data can be clustered naturally in multiple ways. In this paper, we address the difficult problem of uncovering disparate clusterings from the data in a {\em totally unsupervised manner}. We propose two new approaches for this problem. In the first approach we aim to find good clusterings of the data that are also {\em decorrelated} with one another. To this end, we give a new and tractable characterization of decorrelation between clusterings, and present an objective function to capture it. We provide an iterative ``decorrelated'' $k$-means type algorithm to minimize this objective function. In the second approach, we model the data as a sum of mixtures and associate each mixture with a clustering. This approach leads us to the problem of learning a convolution of mixture distributions. Though the latter problem can be formulated as one of factorial learning \cite{zoubin,hinton,mcvq}, the  existing formulations and methods do not perform well on many real high-dimensional data sets. We propose a new regularized factorial learning framework that is more suitable for capturing the notion of disparate clusterings in modern, high-dimensional data sets. The resulting algorithm does well in uncovering multiple clusterings, and is much improved over existing methods.
</div>
</div>
</div>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-7001529-2");
pageTracker._trackPageview();
} catch(err) {}</script>
</body>

</html>
